{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 言語処理100本ノック 2020年\n",
    "\n",
    "[言語処理100本ノック2020版](https://nlp100.github.io/ja/)が公開されたのでこの機会に解いていく。\n",
    "GitHubに公開しているJupyterをmarkdown出力したものなので，一度読み込んだパッケージはその後に読み込んでいないことに注意。\n",
    "\n",
    "## 第3章：正規表現\n",
    "\n",
    "> Wikipediaの記事を以下のフォーマットで書き出したファイルjawiki-country.json.gzがある．\n",
    "  1行に1記事の情報がJSON形式で格納される\n",
    "  各行には記事名が”title”キーに，記事本文が”text”キーの辞書オブジェクト　に格納され，そのオブジェクトがJSON形式で書き出される\n",
    "  ファイル全体はgzipで圧縮される\n",
    "  以下の処理を行うプログラムを作成せよ．\n",
    "\n",
    "内容的には2015と変わらないらしい。\n",
    "Wikiのマークアップは[ここ](https://ja.wikipedia.org/wiki/Help:%E6%97%A9%E8%A6%8B%E8%A1%A8)にまとめられている。\n",
    "\n",
    "### 20. JSONデータの読み込み\n",
    "\n",
    "> Wikipedia記事のJSONファイルを読み込み，「イギリス」に関する記事本文を表示せよ．問題21-29では，ここで抽出した記事本文に対して実行せよ．\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{{redirect|UK}}\n",
      "{{redirect|英国|春秋時代の諸侯国|英 (春秋)}}\n",
      "{{Otheruses|ヨーロッパの国|長崎県・熊本県の郷土料理|いぎりす}}\n",
      "{{基礎情報 国\n",
      "|略名  =イギリス\n",
      "|日本語国名 = グレートブリテン及び北アイルランド連合王国\n",
      "|公式国名 = {{lang|en|United Kingdom of Great Britain and Northern Ireland}}<ref>英語以外での正式国名:<br />\n",
      "*{{lang|gd|An Rìoghachd Aonaichte na Breatainn Mhòr agus Eirinn mu Thuath}}（[[スコットランド・ゲール語]]）\n",
      "*{{lang|cy|Teyrnas Gyfunol Prydain Fawr a Gogledd Iwerddon}}（[[ウェールズ語]]）\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def return_article(fname, article_title):\n",
    "    with open(fname, 'rt') as data_file:\n",
    "        for line in data_file:\n",
    "            data_json = json.loads(line)\n",
    "            if data_json['title'] == article_title:\n",
    "                return data_json['text']\n",
    "\n",
    "file_path = '../data/jawiki-country.json'\n",
    "uk_article = return_article(file_path, 'イギリス')\n",
    "\n",
    "print(uk_article[0:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 21. カテゴリ名を含む行を抽出\n",
    "\n",
    "> 記事中でカテゴリ名を宣言している行を抽出せよ．\n",
    "\n",
    "上記結果の中身を見るとカテゴリは以下のように記載されていた。\n",
    "\n",
    "```\n",
    "[[Category:イギリス|*]]\n",
    "[[Category:イギリス連邦加盟国]]\n",
    "[[Category:英連邦王国|*]]\n",
    "[[Category:G8加盟国]]\n",
    "[[Category:欧州連合加盟国|元]]\n",
    "[[Category:海洋国家]]\n",
    "[[Category:現存する君主国]]\n",
    "[[Category:島国]]\n",
    "[[Category:1801年に成立した国家・領域]]\n",
    "```\n",
    "\n",
    "形式は`[[Category:カテゴリ名|ソートキー]]`という形をとっている。\n",
    "特殊文字を，その特殊な意味を発動させずに使うには，バックスラッシュを使う必要がある。自分は`r'^\\[+Category\\:.+\\]+$'`のように記載した。\n",
    "`re.MULTILINE`とfindallを使うことで，改行ごとにforループを回さなくても検索することができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[Category:イギリス|*]]\n",
      "[[Category:イギリス連邦加盟国]]\n",
      "[[Category:英連邦王国|*]]\n",
      "[[Category:G8加盟国]]\n",
      "[[Category:欧州連合加盟国|元]]\n",
      "[[Category:海洋国家]]\n",
      "[[Category:現存する君主国]]\n",
      "[[Category:島国]]\n",
      "[[Category:1801年に成立した国家・領域]]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_category_row(wiki_text):\n",
    "    p = re.compile(r'^\\[+Category\\:.+\\]+$', re.MULTILINE)\n",
    "    return p.findall(wiki_text)\n",
    "\n",
    "category_rows = extract_category_row(uk_article)\n",
    "for line in category_rows:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 22. カテゴリ名の抽出\n",
    "\n",
    "> 記事のカテゴリ名を(行単位ではなく名前で)抽出せよ。\n",
    "\n",
    "`()`で囲んだ部分だけを抽出することができる。\n",
    "`\\w`でUnicodeの単語文字にマッチさせている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "イギリス\n",
      "イギリス連邦加盟国\n",
      "英連邦王国\n",
      "G8加盟国\n",
      "欧州連合加盟国\n",
      "海洋国家\n",
      "現存する君主国\n",
      "島国\n",
      "1801年に成立した国家\n"
     ]
    }
   ],
   "source": [
    "def extract_category_name(wiki_text):\n",
    "    p = re.compile(r'^\\[+Category\\:(\\w+).+$', re.MULTILINE)\n",
    "    return p.findall(wiki_text)\n",
    "\n",
    "category_name = extract_category_name(uk_article)\n",
    "for line in category_name:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23. セクション構造\n",
    "\n",
    "> 記事中に含まれるセクション名とそのレベル（例えば”== セクション名 ==”なら1）を表示せよ\n",
    "\n",
    "==歴史==\n",
    "こういうのがセクションらしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "レベル: 2 国名\n",
      "レベル: 2 歴史\n",
      "レベル: 2 地理\n",
      "レベル: 3 主要都市\n",
      "レベル: 3 気候\n",
      "レベル: 2 政治\n",
      "レベル: 3 元首\n",
      "レベル: 3 法\n",
      "レベル: 3 内政\n",
      "レベル: 3 地方行政区分\n",
      "レベル: 2 経済\n",
      "レベル: 3 鉱業\n",
      "レベル: 3 農業\n",
      "レベル: 3 貿易\n",
      "レベル: 3 不動産\n",
      "レベル: 3 エネルギー政策\n",
      "レベル: 3 通貨\n",
      "レベル: 3 企業\n",
      "レベル: 4 通信\n",
      "レベル: 2 交通\n",
      "レベル: 3 道路\n",
      "レベル: 3 鉄道\n",
      "レベル: 3 海運\n",
      "レベル: 3 航空\n",
      "レベル: 2 科学技術\n",
      "レベル: 2 国民\n",
      "レベル: 3 言語\n",
      "レベル: 3 宗教\n",
      "レベル: 3 婚姻\n",
      "レベル: 3 移住\n",
      "レベル: 3 教育\n",
      "レベル: 3 医療\n",
      "レベル: 2 文化\n",
      "レベル: 3 食文化\n",
      "レベル: 3 文学\n",
      "レベル: 3 哲学\n",
      "レベル: 3 音楽\n",
      "レベル: 4 ポピュラー音楽\n",
      "レベル: 3 映画\n",
      "レベル: 3 コメディ\n",
      "レベル: 3 国花\n",
      "レベル: 3 世界遺産\n",
      "レベル: 3 祝祭日\n",
      "レベル: 3 スポーツ\n",
      "レベル: 4 サッカー\n",
      "レベル: 4 クリケット\n",
      "レベル: 4 競馬\n",
      "レベル: 4 モータースポーツ\n",
      "レベル: 4 野球\n",
      "レベル: 2 脚注\n",
      "レベル: 2 関連項目\n",
      "レベル: 2 外部リンク\n"
     ]
    }
   ],
   "source": [
    "def extract_section(wiki_text):\n",
    "    result = {}\n",
    "    p = re.compile(r'^(={2,})(\\w+)\\1$', re.MULTILINE)\n",
    "    section_content =  p.findall(wiki_text)\n",
    "    for item in section_content:\n",
    "        result[item[1]] = len(item[0])\n",
    "    return result\n",
    "\n",
    "section_dict = extract_section(uk_article)\n",
    "\n",
    "for k,v in section_dict.items():\n",
    "    print('レベル:',v, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 24. ファイル参照の抽出\n",
    "\n",
    "> 記事から参照されているメディアファイルをすべて抜き出せ.\n",
    "\n",
    "`[[ファイル:Wikipedia-logo-v2-ja.png|thumb|説明文]]`というのがファイルの記載マークアップらしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Royal Coat of Arms of the United Kingdom.svg', 'Descriptio Prime Tabulae Europae.jpg', \"Lenepveu, Jeanne d'Arc au siège d'Orléans.jpg\", 'London.bankofengland.arp.jpg', 'Battle of Waterloo 1815.PNG', 'Uk topo en.jpg', 'BenNevis2005.jpg', 'Population density UK 2011 census.png', '2019 Greenwich Peninsula & Canary Wharf.jpg', 'Birmingham Skyline from Edgbaston Cricket Ground crop.jpg', 'Leeds CBD at night.jpg', 'Glasgow and the Clyde from the air (geograph 4665720).jpg', 'Palace of Westminster, London - Feb 2007.jpg', 'Scotland Parliament Holyrood.jpg', 'Donald Trump and Theresa May (33998675310) (cropped).jpg', 'Soldiers Trooping the Colour, 16th June 2007.jpg', 'City of London skyline from London City Hall - Oct 2008.jpg', 'Oil platform in the North SeaPros.jpg', 'Eurostar at St Pancras Jan 2008.jpg', 'Heathrow Terminal 5C Iwelumo-1.jpg', 'Airbus A380-841 G-XLEB British Airways (10424102995).jpg', 'UKpop.svg', 'Anglospeak.svg', \"Royal Aberdeen Children's Hospital.jpg\", 'CHANDOS3.jpg', 'The Fabs.JPG', 'Wembley Stadium, illuminated.jpg']\n"
     ]
    }
   ],
   "source": [
    "def extract_file(wiki_text):\n",
    "    p = re.compile(r'\\[\\[ファイル\\:(.+?)\\|')\n",
    "    file_name = p.findall(wiki_text)\n",
    "    return file_name\n",
    "\n",
    "file_reference = extract_file(uk_article)\n",
    "print(file_reference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 25. テンプレートの抽出\n",
    "\n",
    "> 記事中に含まれる「基礎情報」テンプレートのフィールド名と値を抽出し，辞書オブジェクトとして格納せよ．\n",
    "\n",
    "基礎情報は以下のようになっている。\n",
    "\n",
    "```\n",
    "{{基礎情報 国\n",
    "|略名  =イギリス\n",
    "|日本語国名 = グレートブリテン及び北アイルランド連合王国\n",
    "|公式国名 = {{lang|en|United Kingdom of Great Britain and Northern Ireland}}<ref>英語以外での正式国名:<br />\n",
    "*{{lang|gd|An Rìoghachd Aonaichte na Breatainn Mhòr agus Eirinn mu Thuath}}（[[スコットランド・ゲール語]]）\n",
    "*{{lang|cy|Teyrnas Gyfunol Prydain Fawr a Gogledd Iwerddon}}（[[ウェールズ語]]）\n",
    "*{{lang|ga|Ríocht Aontaithe na Breataine Móire agus Tuaisceart na hÉireann}}（[[アイルランド語]]）\n",
    "*{{lang|kw|An Rywvaneth Unys a Vreten Veur hag Iwerdhon Glédh}}（[[コーンウォール語]]）\n",
    "*{{lang|sco|Unitit Kinrick o Great Breetain an Northren Ireland}}（[[スコットランド語]]）\n",
    "**{{lang|sco|Claught Kängrick o Docht Brätain an Norlin Airlann}}、{{lang|sco|Unitet Kängdom o Great Brittain an Norlin Airlann}}（アルスター・スコットランド語）</ref>\n",
    "|国旗画像 = Flag of the United Kingdom.svg\n",
    "|国章画像 = [[ファイル:Royal Coat of Arms of the United Kingdom.svg|85px|イギリスの国章]]\n",
    "\n",
    "<<中略>>\n",
    "\n",
    "}}\n",
    "```\n",
    "\n",
    "`|`を頼りに検索するため，先読みアサーション系統を用いた([pythonのドキュメント](https://docs.python.org/ja/3/library/re.html)より以下引用)\n",
    "\n",
    "> (?=...)\n",
    "... が次に続くものにマッチすればマッチしますが、文字列をまったく消費しません。これは 先読みアサーション (lookahead assertion) と呼ばれます。例えば、Isaac (?=Asimov) は 'Isaac ' に、その後に 'Asimov' が続く場合にのみ、マッチします。\n",
    "\n",
    "ここに関しては，[素人の言語処理](https://qiita.com/segavvy/items/e402ad0a5b0f52453d7f)を参考にさせていただいた。\n",
    "全く同じになってもつまらないので，{{基礎情報*}}の部分を抽出しないで書いてみた。ただし，他の例においての応用生が低いので，きちんと抽出してからやったほうがいいと思う。具体的には，直接抽出した際に邪魔になるのが`|style=*`という部分だけだったので，それを除去する形で抽出した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"GDP値\": \"2兆3162億<ref name=\\\"imf-statistics-gdp\\\" />\",\n",
      "    \"GDP値MER\": \"2兆4337億<ref name=\\\"imf-statistics-gdp\\\" />\",\n",
      "    \"GDP値元\": \"1兆5478億<ref name=\\\"imf-statistics-gdp\\\">[http://www.imf.org/external/pubs/ft/weo/2012/02/weodata/weorept.aspx?pr.x=70&pr.y=13&sy=2010&ey=2012&scsm=1&ssd=1&sort=country&ds=.&br=1&c=112&s=NGDP%2CNGDPD%2CPPPGDP%2CPPPPC&grp=0&a=IMF>Data and Statistics>World Economic Ou\n"
     ]
    }
   ],
   "source": [
    "def extract_basic_info(wiki_text):\n",
    "    result = {}\n",
    "    p = re.compile(r'^\\|(?!style)(\\w+?)\\s*\\=\\s*(.+?)(?:(?=\\n\\|))', re.MULTILINE)\n",
    "    basics = p.findall(wiki_text)\n",
    "    for item in basics:\n",
    "        result[item[0]] = item[1]\n",
    "    return result\n",
    "\n",
    "basic_info = extract_basic_info(uk_article)\n",
    "print(json.dumps(basic_info, sort_keys=True, indent=4, ensure_ascii=False)[0:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 26. 強調マークアップの除去\n",
    "\n",
    "> 25の処理時に，テンプレートの値からMediaWikiの強調マークアップ（弱い強調，強調，強い強調のすべて）を除去してテキストに変換せよ（参考: [マークアップ早見表](http://ja.wikipedia.org/wiki/Help:%E6%97%A9%E8%A6%8B%E8%A1%A8)）\n",
    "\n",
    "''強調''のように，二つ以上の'に囲まれているところが強調マークアップである。処理時ということなので新しく重複する処理を行う関数を定義した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"GDP値\": \"2兆3162億<ref name=\\\"imf-statistics-gdp\\\" />\",\n",
      "    \"GDP値MER\": \"2兆4337億<ref name=\\\"imf-statistics-gdp\\\" />\",\n",
      "    \"GDP値元\": \"1兆5478億<ref name=\\\"imf-statistics-gdp\\\">[http://www.imf.org/external/pubs/ft/weo/2012/02/weodata/weorept.aspx?pr.x=70&pr.y=13&sy=2010&ey=2012&scsm=1&ssd=1&sort=country&ds=.&br=1&c=112&s=NGDP%2CNGDPD%2CPPPGDP%2CPPPPC&grp=0&a=IMF>Data and Statistics>World Economic Ou\n"
     ]
    }
   ],
   "source": [
    "def extract_basic_removed_reinforce(wiki_text):\n",
    "    result = {}\n",
    "    ps = re.compile(r'\\'{2,}') # 加えた部分\n",
    "    p = re.compile(r'^\\|(?!style)(\\w+?)\\s*\\=\\s*(.+?)(?:(?=\\n\\|))', re.MULTILINE)\n",
    "    removed_text = ps.sub('', wiki_text) # 加えた部分\n",
    "    basics = p.findall(removed_text)\n",
    "    for item in basics:\n",
    "        result[item[0]] = item[1]\n",
    "    return result\n",
    "\n",
    "basic_info = extract_basic_removed_reinforce(uk_article)\n",
    "print(json.dumps(basic_info, sort_keys=True, indent=4, ensure_ascii=False)[0:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 27. 内部リンクの除去\n",
    "\n",
    "> 26の処理に加えて，テンプレートの値からMediaWikiの内部リンクマークアップを除去し，テキストに変換せよ\n",
    "\n",
    "リンクは\n",
    "\n",
    "```\n",
    "[[記事名]]\n",
    "[[記事名|表示文字]]\n",
    "[[記事名#節名|表示文字]]\n",
    "```\n",
    "\n",
    "の３種類がある。処理する際に巻き込みそうな他のwikiマークアップとしては，カテゴリやファイル指定，リダイレクト要素がある。記事にredirectが見当たらなかったので，categoryとファイル指定の除去だけ考える。\n",
    "ここまで，全て一つの関数で行っているが，本来なら基礎助用法の読み取りなど，一つ一つを別の関数に定義するべきである，と思う。\n",
    "\n",
    "```\n",
    "[[Category:ヘルプ|はやみひよう]]\n",
    "[[ファイル:Wikipedia-logo-v2-ja.png|thumb|説明文]]\n",
    "#REDIRECT [[記事名]]\n",
    "#REDIRECT [[記事名#節名]]\n",
    "```\n",
    "\n",
    "`?!`：当てはまらない時に正\n",
    "`?:`：キャプチャしないところを指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"GDP値\": \"2兆3162億<ref name=\\\"imf-statistics-gdp\\\" />\",\n",
      "    \"GDP値MER\": \"2兆4337億<ref name=\\\"imf-statistics-gdp\\\" />\",\n",
      "    \"GDP値元\": \"1兆5478億<ref name=\\\"imf-statistics-gdp\\\">[http://www.imf.org/external/pubs/ft/weo/2012/02/weodata/weorept.aspx?pr.x=70&pr.y=13&sy=2010&ey=2012&scsm=1&ssd=1&sort=country&ds=.&br=1&c=112&s=NGDP%2CNGDPD%2CPPPGDP%2CPPPPC&grp=0&a=IMF>Data and Statistics>World Economic Ou\n"
     ]
    }
   ],
   "source": [
    "# リンク除去の関数\n",
    "def remove_links(text):\n",
    "    p = re.compile(r'\\[\\[(?!Category\\:ファイル)(?:[^|]*?\\|)?([^|]*?)\\]\\]')\n",
    "    return p.sub(r'\\1', text)\n",
    "\n",
    "def extract_basic_not_link_reinforce(wiki_text):\n",
    "    result = {}\n",
    "    ps = re.compile(r'\\'{2,}') \n",
    "    p = re.compile(r'^\\|(?!style)(\\w+?)\\s*\\=\\s*(.+?)(?:(?=\\n\\|))', re.MULTILINE) \n",
    "    removed_text = remove_links(ps.sub('', wiki_text)) #　変更した部分\n",
    "    basics = p.findall(removed_text)\n",
    "    for item in basics:\n",
    "        result[item[0]] = item[1]\n",
    "    return result\n",
    "\n",
    "basic_info = extract_basic_not_link_reinforce(uk_article)\n",
    "print(json.dumps(basic_info, sort_keys=True, indent=4, ensure_ascii=False)[0:400])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 28. MediaWikiマークアップの除去\n",
    "\n",
    "> 27の処理に加えて，テンプレートの値からMediaWikiマークアップを可能な限り除去し，国の基本情報を整形せよ．\n",
    "\n",
    "残っている除去項目は，\n",
    "27であえて残したファイルと内部リンクの除去，\n",
    "langタグの除去，\n",
    "<br/>タグ，<ref>タグの除去\n",
    "    \n",
    "基本情報の抜き出しから改めて定義して行ってみる。cite webやcenterがまだ取り出せていないので修正する必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"GDP値\": \"2兆3162億\",\n",
      "    \"GDP値MER\": \"2兆4337億\",\n",
      "    \"GDP値元\": \"1兆5478億and Statistics>World Economic Outlook Databases>By Countrise>United Kingdom\",\n",
      "    \"GDP統計年\": \"2012\",\n",
      "    \"GDP統計年MER\": \"2012\",\n",
      "    \"GDP統計年元\": \"2012\",\n",
      "    \"GDP順位\": \"6\",\n",
      "    \"GDP順位MER\": \"6\",\n",
      "    \"ccTLD\": \".uk / .gb使用は.ukに比べ圧倒的少数。\",\n",
      "    \"人口値\": \"6643万5600{{Cite web|url=https://www.ons.gov.uk/peoplepopulationandcommunity/populationan\n"
     ]
    }
   ],
   "source": [
    "# 基礎情報の抽出\n",
    "def extract_basic(text):\n",
    "    p = re.compile(r'^\\|(?!style)(\\w+?)\\s*\\=\\s*(.+?)(?:(?=\\n\\|))', re.MULTILINE)\n",
    "    basics = p.findall(text)\n",
    "    return basics\n",
    "\n",
    "# 除去関数\n",
    "def remove_emphasis(text):\n",
    "    p = re.compile(r'\\'{2,}')\n",
    "    return p.sub(r'', text)\n",
    "def remove_links(text):\n",
    "    p = re.compile(r'\\[\\[(?:[^|]*?\\|)*?([^|]*?)\\]\\]')\n",
    "    return p.sub(r'\\1', text)\n",
    "def remove_tags(text):\n",
    "    p = re.compile(r'<[^>]*?>')\n",
    "    return p.sub(r'', text)\n",
    "def remove_lang(text):\n",
    "    p = re.compile(r'\\{\\{lang(?:[^|]*?\\|)*?([^|]*?)\\}\\}')\n",
    "    return p.sub(r'\\1', text)\n",
    "def remove_ex_link(text):\n",
    "    p = re.compile(r'\\[http:\\/\\/(?:[^\\s]*?)\\s([^]]*?)\\]')\n",
    "    return p.sub(r'\\1', text)\n",
    "\n",
    "\n",
    "def main():\n",
    "    basic_dict = {}\n",
    "    basic_list = extract_basic(uk_article)\n",
    "    for target in basic_list:\n",
    "        explanation = remove_emphasis(target[1])\n",
    "        explanation = remove_links(explanation)\n",
    "        explanation = remove_tags(explanation)\n",
    "        explanation = remove_lang(explanation)\n",
    "        explanation = remove_ex_link(explanation)\n",
    "        basic_dict[target[0]] = explanation\n",
    "    print(json.dumps(basic_dict, sort_keys=True, indent=4, ensure_ascii=False)[0:400])\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 29. 国旗画像のURLを取得する\n",
    "\n",
    "> テンプレートの内容を利用し，国旗画像のURLを取得せよ．（ヒント: [MediaWiki API](http://www.mediawiki.org/wiki/API:Main_page/ja)の[imageinfo](https://www.mediawiki.org/wiki/API:Imageinfo)を呼び出して，ファイル参照をURLに変換すればよい）\n",
    "\n",
    "28の時点で`\"国旗画像\": \"Flag of the United Kingdom.svg\"`が取得できている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://upload.wikimedia.org/wikipedia/en/a/ae/Flag_of_the_United_Kingdom.svg\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def extract_basic_dict(article):\n",
    "    basic_dict = {}\n",
    "    basic_list = extract_basic(article)\n",
    "    for target in basic_list:\n",
    "        explanation = remove_emphasis(target[1])\n",
    "        explanation = remove_links(explanation)\n",
    "        explanation = remove_tags(explanation)\n",
    "        explanation = remove_lang(explanation)\n",
    "        explanation = remove_ex_link(explanation)\n",
    "        basic_dict[target[0]] = explanation\n",
    "    return basic_dict\n",
    "\n",
    "basic_dict = extract_basic_dict(uk_article)\n",
    "fname_flag = basic_dict['国旗画像']\n",
    "\n",
    "def obtain_url(basic_dict, title):\n",
    "    fname_flag = basic_dict[title].replace(' ', '_')\n",
    "    url = 'https://en.wikipedia.org/w/api.php?' \\\n",
    "        + 'action=query' \\\n",
    "        + '&titles=File:' + fname_flag \\\n",
    "        + '&prop=imageinfo' \\\n",
    "        + '&iiprop=url' \\\n",
    "        + '&format=json'\n",
    "    data = requests.get(url)\n",
    "    return re.search(r'\"url\":\"(.+?)\"', data.text).group(1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    basic_dict = extract_basic_dict(uk_article)\n",
    "    query_url = obtain_url(basic_dict, \"国旗画像\")\n",
    "    print(query_url)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

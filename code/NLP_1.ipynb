{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 言語処理100本ノック 2020年\n",
    "\n",
    "## 第1章：準備運動 \n",
    "\n",
    "[言語処理100本ノック2020版](https://nlp100.github.io/ja/)が公開されたのでこの機会に解いていく。\n",
    "自分のjupyter notebookをmarkdownに起こしたものなので，説明は少なくなってしまっています。少しでも参考になればと思い，ブログとGitHubにまとめる予定のものをQiitaにも投稿してみました。\n",
    "\n",
    "こんな素晴らしい教材を提供していただける先生方に頭が上がりません。\n",
    "\n",
    "### 00.文字列の逆順 \n",
    "\n",
    "文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "desserts\n"
     ]
    }
   ],
   "source": [
    "def reverseStrings(s):\n",
    "    return s[::-1]\n",
    "\n",
    "print(reverseStrings(\"stressed\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01.パトカータクシー\n",
    "\n",
    "> 「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パカタシー\n"
     ]
    }
   ],
   "source": [
    "def extractStrings(s):\n",
    "    return s[::2]\n",
    "\n",
    "print(extractStrings(\"パトカータクシーー\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02.「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "\n",
    "> 「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "パタトクカシーー\n"
     ]
    }
   ],
   "source": [
    "# 同じ長さの文字列でしか使えない\n",
    "def connectStrings(sone, stwo):\n",
    "    result = \"\".join(s1+s2 for s1,s2 in zip(sone, stwo))\n",
    "    return result\n",
    "\n",
    "print(connectStrings(\"パトカー\", \"タクシー\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. 円周率\n",
    "\n",
    "> “Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．\n",
    "\n",
    "出力結果が円周率になる。\n",
    "綺麗に書くのに迷ったが，正規表現でコンマとピリオドを除去するこでできるだけ短くしたつもり。\n",
    "文字数カウントは`map`を用いてfor文を回さずに処理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def permalink(s):\n",
    "    splited = re.split('\\s', re.sub(r'[,.]',  '', s))\n",
    "    words_len = list(map(len, splited))\n",
    "    return words_len\n",
    "\n",
    "sentence = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "print(permalink(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04.元素記号\n",
    "\n",
    "> “Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ\n",
    "\n",
    "zipや内包表記を使ってもっと綺麗に書けるはず。いい方法あれば教えていただけると幸いです。。．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
     ]
    }
   ],
   "source": [
    "def elementSymbol(s, number):\n",
    "    out_dict = {}\n",
    "    splited = re.split('\\s', s)\n",
    "    for i, w in enumerate(splited):\n",
    "        if i+1 in number:\n",
    "            out_dict[w[:1]] = i + 1\n",
    "        else :\n",
    "            out_dict[w[:2]] = i + 1\n",
    "            \n",
    "    return out_dict\n",
    "\n",
    "sentence = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "only_first_number = [1, 5, 6, 7, 8, 9, 15, 16, 19]\n",
    "print(elementSymbol(sentence, only_first_number))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05.n-gram\n",
    "\n",
    "> 与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．\n",
    "\n",
    "N-gramとは，wikiによると下記\n",
    "\n",
    "> 検索対象を単語単位ではなく文字単位で分解し、後続の N-1 文字を含めた状態で出現頻度を求める方法。 Nの値が1なら「ユニグラム（英: uni-gram）」、2なら「バイグラム（英: bi-gram）」、3なら「トライグラム（英: tri-gram）」と呼ばれる。\n",
    "\n",
    "~~今回は，単語n-gramと文字n-gramを別の関数として実装することにした。~~ 与える文字列を`split`で区切り，リストとして渡せば汎用的に使えた。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "単語bi-gram : [['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n",
      "文字bi-gram : ['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n"
     ]
    }
   ],
   "source": [
    "def generateNGram(sentence, N):\n",
    "    return [sentence[i:i+N] for i in range(len(sentence) - N + 1)]\n",
    "\n",
    "input_text = \"I am an NLPer\"\n",
    "\n",
    "print(\"単語bi-gram : \" + str(generateNGram(input_text.split(' '), 2)))\n",
    "print(\"文字bi-gram : \" + str(generateNGram(input_text, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 06. 集合\n",
    "\n",
    "> “paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "和集合 : {'se', 'is', 'gr', 'ra', 'ap', 'ad', 'ph', 'pa', 'ag', 'ar', 'di'}\n",
      "積集合 : {'ra', 'ap', 'pa', 'ar'}\n",
      "差集合 : {'se', 'is', 'ad', 'di'}\n",
      "seがXに含まれるか : True\n",
      "seがYに含まれるか : False\n"
     ]
    }
   ],
   "source": [
    "X_text = \"paraparaparadise\"\n",
    "Y_text = \"paragraph\"\n",
    "\n",
    "X = set(generateNGram(X_text, 2))\n",
    "Y = set(generateNGram(Y_text, 2))\n",
    "\n",
    "print(\"和集合 : \" + str(X.union(Y)))\n",
    "print(\"積集合 : \" + str(X.intersection(Y)))\n",
    "print(\"差集合 : \" + str(X.difference(Y)))\n",
    "\n",
    "print(\"seがXに含まれるか : \" + str('se' in X))\n",
    "print(\"seがYに含まれるか : \" + str('se' in Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 07.テンプレートによる文生成\n",
    "\n",
    "> 引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．\n",
    "\n",
    "python 3.6以前だと`f-string`を用いることができないので注意.逆にいうとそれ以前の記事だと`f-string`を用いていない。基本情報は[ここ](https://ohshige.hatenablog.com/entry/2019/02/11/190000)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12時の気温は22.4\n"
     ]
    }
   ],
   "source": [
    "def generateTemp(x, y, z):\n",
    "    return f\"{x}時の{y}は{z}\"\n",
    "\n",
    "print(generateTemp(12, \"気温\", 22.4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 08.暗号文\n",
    "\n",
    "> 与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n",
    "  ・ 英小文字ならば(219 - 文字コード)の文字に置換\n",
    "  ・その他の文字はそのまま出力\n",
    "  この関数を用い，英語のメッセージを暗号化・復号化せよ．\n",
    "  \n",
    "組み込み関数`ord()`で文字のUnicodeコードポイントを取得できるらしいので使ってみた。\n",
    "小文字に一致するものを変換すればいいので，正規表現で置換するのが早い。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hr, Tszmp blf uli ivzwrmt nb zigrxov!!\n",
      "Hi, Thank you for reading my article!!\n"
     ]
    }
   ],
   "source": [
    "def chipher(s):\n",
    "    result = \"\"\n",
    "    for character in s:\n",
    "        result += re.sub(r'[a-z]', chr(219 - ord(character)), character)\n",
    "    return result\n",
    "\n",
    "\n",
    "sentence = \"Hi, Thank you for reading my article!!\"\n",
    "print(chipher(sentence))\n",
    "print(chipher(chipher(sentence)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[@suzu6](https://www.suzu6.net/posts/17/)さんが`lambda`式を使い，もっと綺麗に解かれていた。というより，正規表現で置換するのに`for`ループを回すのはあまり良くなかった。\n",
    "以下の例では，mが[マッチオブジェクト](https://note.nkmk.me/python-re-match-object-span-group/)であり，マッチした文字列を取得するのに`group()`を使用する必要がある。`group(0)`でマッチした文字列全体を取得する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hr Hv Lrvw Bvxzfhv Blilm Clfow Nlg Ocrwrav Foflirmv. Nvd Nzgrlmh Mrtsg Aohl Srtm Pvzxv Svxfirgb Cozfhv. Aigsfi Krmt Czm.\n"
     ]
    }
   ],
   "source": [
    "def cipher(src):\n",
    "    return re.sub(r'[a-z]', lambda m: chr(219 - ord(m.group(0))), src)\n",
    "\n",
    "text = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "\n",
    "# 暗号化\n",
    "print(cipher(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 09.Typoglycemia\n",
    "\n",
    "> スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind.”）を与え，その実行結果を確認せよ．\n",
    "\n",
    "リスト内包表記にしない方が綺麗だったと思うが，練習としてちょうどいい長さだったのでリスト内包表記を用いた。\n",
    "何となく読めてしまう文章が出力される。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I cun’ldot bilveee taht I culod alclatuy uersnatndd what I was rideang : the peaeohnmnl pewor of the hamun mdin.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def mixingWord(sentence):\n",
    "    splited = sentence.split(\" \")     \n",
    "    randomed_list = [ s[0] + ''.join(random.sample(s[1:-1], len(s)-2)) + s[-1] if len(s) >= 4 else s for s in splited]\n",
    "    return \" \".join(randomed_list)\n",
    "\n",
    "input_text = \"I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind.\"\n",
    "mixingWord(input_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
